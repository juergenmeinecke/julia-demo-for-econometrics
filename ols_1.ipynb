{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7: Everything in Code\n",
    "Today I will show you how to write up OLS estimation in Julia code.\n",
    "\n",
    "I'm choosing Julia because it let's me implement everything using linear algebra. So instead of resorting to a canned command, such as Stata's \"regress Y X\" the point here is to be explicit about what's going on under the hood.\n",
    "\n",
    "When you type \"regress Y X\" in Stata then magically the results appear. But where do they come from? Under the hood Stata is doing what we will be doing here by using Julia.\n",
    "\n",
    "I will present three different Jupyter notebooks to you, at increasing level of abstraction and complexity. \n",
    "\n",
    "* ols_1: a primitive OLS implementation to expose you to the main idea\n",
    "\n",
    "* ols_2: does exactly the same thing as ols_1, but slightly more abstract to prepare you for ols_3\n",
    "\n",
    "* ols_3: highest level of abstraction and highest degree of flexibility, allows us to do Monte Carlo simulations.\n",
    "\n",
    "In all three codes I'm doing something funny: I'm creating my own data!\n",
    "\n",
    "In real life you usually deal with one random sample that is given to you. For example, you observe ordered pairs of earnings and schooling and, in Stata, you would do something like \"regress earnings schooling\" to estimate the projection coefficient in the linear projection of earnings on schooling. The underlying model for this estimation is\n",
    "\n",
    "$$\n",
    "earnings = \\beta_0 + \\beta_1 schooling + e, \\qquad E(e \\cdot schooling) = 0\n",
    "$$\n",
    "\n",
    "My interpretation of this model is this: schooling and $e$ are random variables that generate the random variable earnings according to the linear model $\\beta_0 + \\beta_1 schooling + e$. The random sample consists of $N$ realizations of the ordered pairs (schooling, earnings) and my goal is to estimate $\\beta_1$.\n",
    "\n",
    "When I create my own random sample, here is what I do: I generate $N$ realizations for the random variables $X$ and $e$ (using statistical distributions of my own choosing) and then generate $Y$ based on $\\beta_0 + \\beta_1 X + e$. For this I need to \"know\" these things:\n",
    " \n",
    "* the statistical distributions of $X$ and $e$\n",
    "\n",
    "* the coefficients $\\beta_0$ and $\\beta_1$\n",
    "\n",
    "(I don't \"know\" these. Instead I \"create\" or \"choose\" these. I'm assuming the role of the oracle!)\n",
    "\n",
    "Then I pretend I only observe $N$ realizations of ordered pairs $(X,Y)$ and estimate $\\beta_1$.\n",
    "\n",
    "Why do I estimate $\\beta_1$ when I created it in the first place? It gives me the opportunity to evaluate numerically if a particular estimation method is good. For example, if I set $\\beta=5$ and I estimate $\\hat{\\beta}=42$ then I suspect that my estimator is not very good. You will hopefully understand the idea of these simulation exercises once we have worked through all three OLS notebooks. Bear with me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generating Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I am creating the sample data according to a *true* model of my creation. In other words, I am \"creating\" or \"choosing\" the true model.\n",
    "\n",
    "Consider the simple one equation model\n",
    "\n",
    "\\begin{align}\n",
    "Y &= \\beta_0 + \\beta_1 X + e\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "All variables are scalars for simplicity. \n",
    "\n",
    "The variable $X$ is generated given the following information:\n",
    "\n",
    "* $X \\sim N(0,1)$\n",
    "\n",
    "* $e \\sim N(0,1)$\n",
    "    \n",
    "* $\\beta_0 = 24$ and $\\beta_1=8$ (the particular values here are irrelevant, I picked these for no good reason)\n",
    "\n",
    "* sample size $N=1000$\n",
    "\n",
    "Note that I could have chosen any statistical distribution for $X$ and $e$, they also don't have to have the same distribution of course. Also notice that I effectively create $X$ to be statistically independent of $e$, so the linear projection model is adequate. No endogeneity here. Yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation in Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading modules\n",
    "using LinearAlgebra\n",
    "using Statistics\n",
    "using Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting parameters and creating sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters\n",
    "N = 1000 # sample size\n",
    "beta_0 = 24 # intercept\n",
    "beta_1 = 8 # slope\n",
    "\n",
    "# creating sample\n",
    "Random.seed!(42) # fixing random numbers for cross-code comparison\n",
    "\n",
    "# exogenous variables: simply set as normal rvs\n",
    "X = [ones(N, 1) randn(N)]\n",
    "e = randn(N) \n",
    "    \n",
    "# creating endogenous variables    \n",
    "Y = X*[beta_0; beta_1] + e;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation (OLS estimator, Avar, se, ci)\n",
    "Remember the following results from our lecture:\n",
    "\n",
    "* $\\hat{\\beta} = (X'X)^{-1} X'Y$\n",
    "\n",
    "* $\\sqrt{N} (\\hat{\\beta}-\\beta) \\to_d N(0,\\Omega)$ where $\\Omega \\in \\{\\Omega_{hom}, \\Omega_{het} \\}$\n",
    "\n",
    "    * $\\Omega_{hom} = \\sigma_e^2 E(X_i X_i')^{-1}$\n",
    "    \n",
    "    * $\\Omega_{het} = E(X_i X_i')^{-1} E(e_i^2 X_i X_i') E(X_i X_i')^{-1}$\n",
    "    \n",
    "The practical meaning of the asymptotic distribution is this:\n",
    "\n",
    "* $\\hat{\\beta} \\overset{approx}{\\sim} N(\\beta, \\hat{\\Omega}/N)$ where\n",
    "\n",
    "    * $\\hat{\\Omega}_{hom} := s_e^2 \\cdot (X'X/N)^{-1}$\n",
    "    \n",
    "    * $\\hat{\\Omega}_{het} := (X'X/N)^{-1} \\cdot (X' diag(\\hat{e}^2) X/N) \\cdot (X'X/N)^{-1}$\n",
    "    \n",
    "    * $s_e^2 := \\hat{e}' \\hat{e}/N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS estimator:  [24.015845699885638, 8.047945398812304]\n"
     ]
    }
   ],
   "source": [
    "# OLS estimation\n",
    "\n",
    "bols = inv(X'*X)*X'*Y;\n",
    "println(\"OLS estimator:  \", bols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se homosk.:   [0.031154794344993554, 0.030061293182925403]\n",
      "se hetersk.:  [0.031240701084897, 0.02878034246262317]\n"
     ]
    }
   ],
   "source": [
    "# Asymptotic variance estimation\n",
    "\n",
    "ehat = Y - X*bols;\n",
    "shat = ehat'*ehat/length(ehat);\n",
    "\n",
    "Omegahat_hom = shat[1]*inv(X'*X);\n",
    "Omegahat_het = inv(X'*X) * (X'*Diagonal(ehat.^2)*X) * inv(X'*X);\n",
    "\n",
    "se_hom = diag(Omegahat_hom).^(0.5);\n",
    "se_het = diag(Omegahat_het).^(0.5);\n",
    "\n",
    "println(\"se homosk.:   \", se_hom)\n",
    "println(\"se hetersk.:  \", se_het)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf interval homosk:   [7.989025264173771, 8.106865533450838]\n",
      "conf interval heterosk: [7.991535927585563, 8.104354870039046]\n"
     ]
    }
   ],
   "source": [
    "# Confidence interval\n",
    "\n",
    "ci_hom = [bols[2] - 1.96*se_hom[2]; bols[2] + 1.96*se_hom[2]];\n",
    "ci_het = [bols[2] - 1.96*se_het[2]; bols[2] + 1.96*se_het[2]];\n",
    "println(\"conf interval homosk:   \", ci_hom)\n",
    "println(\"conf interval heterosk: \", ci_het)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
